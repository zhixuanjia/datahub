"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[6539],{4137:function(e,a,t){t.d(a,{Zo:function(){return d},kt:function(){return m}});var n=t(7294);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function o(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?o(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function l(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=n.createContext({}),u=function(e){var a=n.useContext(s),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},d=function(e){var a=u(e.components);return n.createElement(s.Provider,{value:a},e.children)},p={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},c=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),c=u(t),m=r,f=c["".concat(s,".").concat(m)]||c[m]||p[m]||o;return t?n.createElement(f,i(i({ref:a},d),{},{components:t})):n.createElement(f,i({ref:a},d))}));function m(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=c;var l={};for(var s in a)hasOwnProperty.call(a,s)&&(l[s]=a[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var u=2;u<o;u++)i[u]=t[u];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}c.displayName="MDXCreateElement"},9024:function(e,a,t){t.r(a),t.d(a,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return u},toc:function(){return d},default:function(){return c}});var n=t(7462),r=t(3366),o=(t(7294),t(4137)),i=["components"],l={title:"Airflow Integration",sidebar_label:"Airflow Integration",slug:"/lineage/airflow",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/lineage/airflow.md"},s="Airflow Integration",u={unversionedId:"docs/lineage/airflow",id:"docs/lineage/airflow",isDocsHomePage:!1,title:"Airflow Integration",description:"DataHub supports integration of",source:"@site/genDocs/docs/lineage/airflow.md",sourceDirName:"docs/lineage",slug:"/lineage/airflow",permalink:"/docs/lineage/airflow",editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/lineage/airflow.md",tags:[],version:"current",frontMatter:{title:"Airflow Integration",sidebar_label:"Airflow Integration",slug:"/lineage/airflow",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/lineage/airflow.md"},sidebar:"overviewSidebar",previous:{title:"Using DataHub",permalink:"/docs/metadata-ingestion/schedule_docs/datahub"},next:{title:"Running Airflow locally with DataHub",permalink:"/docs/docker/airflow/local_airflow"}},d=[{value:"Using Datahub&#39;s Airflow lineage backend (recommended)",id:"using-datahubs-airflow-lineage-backend-recommended",children:[],level:2},{value:"Setting up Airflow to use DataHub as Lineage Backend",id:"setting-up-airflow-to-use-datahub-as-lineage-backend",children:[],level:2},{value:"Emitting lineage via a separate operator",id:"emitting-lineage-via-a-separate-operator",children:[],level:2}],p={toc:d};function c(e){var a=e.components,t=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,n.Z)({},p,t,{components:a,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"airflow-integration"},"Airflow Integration"),(0,o.kt)("p",null,"DataHub supports integration of "),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Airflow Pipeline (DAG) metadata"),(0,o.kt)("li",{parentName:"ul"},"DAG and Task run information as well as "),(0,o.kt)("li",{parentName:"ul"},"Lineage information when present")),(0,o.kt)("p",null,"There are a few ways to enable these integrations from Airflow into DataHub."),(0,o.kt)("h2",{id:"using-datahubs-airflow-lineage-backend-recommended"},"Using Datahub's Airflow lineage backend (recommended)"),(0,o.kt)("div",{className:"admonition admonition-caution alert alert--warning"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"}))),"caution")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"The Airflow lineage backend is only supported in Airflow 1.10.15+ and 2.0.2+."))),(0,o.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"If you are looking to run Airflow and DataHub using docker locally, follow the guide ",(0,o.kt)("a",{parentName:"p",href:"/docs/docker/airflow/local_airflow"},"here"),". Otherwise proceed to follow the instructions below."))),(0,o.kt)("h2",{id:"setting-up-airflow-to-use-datahub-as-lineage-backend"},"Setting up Airflow to use DataHub as Lineage Backend"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"You need to install the required dependency in your airflow. See ",(0,o.kt)("a",{parentName:"li",href:"https://registry.astronomer.io/providers/datahub/modules/datahublineagebackend"},"https://registry.astronomer.io/providers/datahub/modules/datahublineagebackend"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"  pip install acryl-datahub[airflow]\n")),(0,o.kt)("ol",{start:2},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"You must configure an Airflow hook for Datahub. We support both a Datahub REST hook and a Kafka-based hook, but you only need one."),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"# For REST-based:\nairflow connections add  --conn-type 'datahub_rest' 'datahub_rest_default' --conn-host 'http://localhost:8080'\n# For Kafka-based (standard Kafka sink config can be passed via extras):\nairflow connections add  --conn-type 'datahub_kafka' 'datahub_kafka_default' --conn-host 'broker:9092' --conn-extra '{}'\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Add the following lines to your ",(0,o.kt)("inlineCode",{parentName:"p"},"airflow.cfg")," file."),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-ini"},'[lineage]\nbackend = datahub_provider.lineage.datahub.DatahubLineageBackend\ndatahub_kwargs = {\n    "datahub_conn_id": "datahub_rest_default",\n    "cluster": "prod",\n    "capture_ownership_info": true,\n    "capture_tags_info": true,\n    "graceful_exceptions": true }\n# The above indentation is important!\n')),(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Configuration options:")),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"datahub_conn_id")," (required): Usually ",(0,o.kt)("inlineCode",{parentName:"li"},"datahub_rest_default")," or ",(0,o.kt)("inlineCode",{parentName:"li"},"datahub_kafka_default"),", depending on what you named the connection in step 1."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"cluster"),' (defaults to "prod"): The "cluster" to associate Airflow DAGs and tasks with.'),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"capture_ownership_info")," (defaults to true): If true, the owners field of the DAG will be capture as a DataHub corpuser."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"capture_tags_info")," (defaults to true): If true, the tags field of the DAG will be captured as DataHub tags."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"capture_executions")," (defaults to false): If true, it captures task runs as DataHub DataProcessInstances. ",(0,o.kt)("strong",{parentName:"li"},"This feature only works with Datahub GMS version v0.8.33 or greater.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"graceful_exceptions")," (defaults to true): If set to true, most runtime errors in the lineage backend will be suppressed and will not cause the overall task to fail. Note that configuration issues will still throw exceptions."))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Configure ",(0,o.kt)("inlineCode",{parentName:"p"},"inlets")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"outlets")," for your Airflow operators. For reference, look at the sample DAG in ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub_provider/example_dags/lineage_backend_demo.py"},(0,o.kt)("inlineCode",{parentName:"a"},"lineage_backend_demo.py")),", or reference ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub_provider/example_dags/lineage_backend_taskflow_demo.py"},(0,o.kt)("inlineCode",{parentName:"a"},"lineage_backend_taskflow_demo.py"))," if you're using the ",(0,o.kt)("a",{parentName:"p",href:"https://airflow.apache.org/docs/apache-airflow/stable/concepts/taskflow.html"},"TaskFlow API"),".")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"[optional]"," Learn more about ",(0,o.kt)("a",{parentName:"p",href:"https://airflow.apache.org/docs/apache-airflow/stable/lineage.html"},"Airflow lineage"),", including shorthand notation and some automation."))),(0,o.kt)("h2",{id:"emitting-lineage-via-a-separate-operator"},"Emitting lineage via a separate operator"),(0,o.kt)("p",null,"Take a look at this sample DAG:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub_provider/example_dags/lineage_emission_dag.py"},(0,o.kt)("inlineCode",{parentName:"a"},"lineage_emission_dag.py"))," - emits lineage using the DatahubEmitterOperator.")),(0,o.kt)("p",null,"In order to use this example, you must first configure the Datahub hook. Like in ingestion, we support a Datahub REST hook and a Kafka-based hook. See step 1 above for details."))}c.isMDXComponent=!0}}]);