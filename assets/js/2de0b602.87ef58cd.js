"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[6460],{4137:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return m}});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),d=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},c=function(e){var t=d(e.components);return a.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=d(n),m=o,h=p["".concat(l,".").concat(m)]||p[m]||u[m]||i;return n?a.createElement(h,r(r({ref:t},c),{},{components:n})):a.createElement(h,r({ref:t},c))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,r=new Array(i);r[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,r[1]=s;for(var d=2;d<i;d++)r[d]=n[d];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},949:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return d},toc:function(){return c},default:function(){return p}});var a=n(7462),o=n(3366),i=(n(7294),n(4137)),r=["components"],s={title:"Adding a Metadata Ingestion Source",sidebar_label:"Adding a Metadata Ingestion Source",slug:"/metadata-ingestion/adding-source",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/adding-source.md"},l="Adding a Metadata Ingestion Source",d={unversionedId:"metadata-ingestion/adding-source",id:"metadata-ingestion/adding-source",isDocsHomePage:!1,title:"Adding a Metadata Ingestion Source",description:"There are two ways of adding a metadata ingestion source.",source:"@site/genDocs/metadata-ingestion/adding-source.md",sourceDirName:"metadata-ingestion",slug:"/metadata-ingestion/adding-source",permalink:"/docs/metadata-ingestion/adding-source",editUrl:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/adding-source.md",tags:[],version:"current",frontMatter:{title:"Adding a Metadata Ingestion Source",sidebar_label:"Adding a Metadata Ingestion Source",slug:"/metadata-ingestion/adding-source",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/adding-source.md"},sidebar:"overviewSidebar",previous:{title:"Lineage sample code",permalink:"/docs/lineage/sample_code"},next:{title:"Using a Custom Ingestion Source",permalink:"/docs/how/add-custom-ingestion-source"}},c=[{value:"1. Set up the configuration model",id:"1-set-up-the-configuration-model",children:[{value:"Documentation for Configuration Classes",id:"documentation-for-configuration-classes",children:[],level:4}],level:3},{value:"2. Set up the reporter",id:"2-set-up-the-reporter",children:[],level:3},{value:"3. Implement the source itself",id:"3-implement-the-source-itself",children:[],level:3},{value:"4. Set up the dependencies",id:"4-set-up-the-dependencies",children:[],level:3},{value:"5. Enable discoverability",id:"5-enable-discoverability",children:[],level:3},{value:"6. Write tests",id:"6-write-tests",children:[],level:3},{value:"7. Write docs",id:"7-write-docs",children:[{value:"7.1 Set up the source class for automatic documentation",id:"71-set-up-the-source-class-for-automatic-documentation",children:[],level:4},{value:"7.2 Write custom documentation",id:"72-write-custom-documentation",children:[],level:4},{value:"7.3 Viewing the Documentation",id:"73-viewing-the-documentation",children:[{value:"Step 1: Build the Ingestion docs",id:"step-1-build-the-ingestion-docs",children:[],level:5}],level:4},{value:"Step 2: Build the Entire Documentation",id:"step-2-build-the-entire-documentation",children:[],level:4}],level:3},{value:"8. Add SQL Alchemy mapping (if applicable)",id:"8-add-sql-alchemy-mapping-if-applicable",children:[],level:3},{value:"9. Add logo for the platform",id:"9-add-logo-for-the-platform",children:[],level:3}],u={toc:c};function p(e){var t=e.components,s=(0,o.Z)(e,r);return(0,i.kt)("wrapper",(0,a.Z)({},u,s,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"adding-a-metadata-ingestion-source"},"Adding a Metadata Ingestion Source"),(0,i.kt)("p",null,"There are two ways of adding a metadata ingestion source."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"You are going to contribute the custom source directly to the Datahub project."),(0,i.kt)("li",{parentName:"ol"},"You are writing the custom source for yourself and are not going to contribute back (yet).")),(0,i.kt)("p",null,"If you are going for case (1) just follow the steps 1 to 9 below. In case you are building it for yourself you can skip\nsteps 4-9 (but maybe write tests and docs for yourself as well) and follow the documentation\non ",(0,i.kt)("a",{parentName:"p",href:"/docs/how/add-custom-ingestion-source"},"how to use custom ingestion sources"),"\nwithout forking Datahub."),(0,i.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"This guide assumes that you've already followed the metadata ingestion ",(0,i.kt)("a",{parentName:"p",href:"/docs/metadata-ingestion/developing"},"developing guide")," to set up\nyour local environment."))),(0,i.kt)("h3",{id:"1-set-up-the-configuration-model"},"1. Set up the configuration model"),(0,i.kt)("p",null,"We use ",(0,i.kt)("a",{parentName:"p",href:"https://pydantic-docs.helpmanual.io/"},"pydantic")," for configuration, and all models must inherit\nfrom ",(0,i.kt)("inlineCode",{parentName:"p"},"ConfigModel"),". The ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/file.py"},"file source")," is a good example."),(0,i.kt)("h4",{id:"documentation-for-configuration-classes"},"Documentation for Configuration Classes"),(0,i.kt)("p",null,"We use ",(0,i.kt)("a",{parentName:"p",href:"https://pydantic-docs.helpmanual.io"},"pydantic")," conventions for documenting configuration flags. Use the ",(0,i.kt)("inlineCode",{parentName:"p"},"description")," attribute to write rich documentation for your configuration field."),(0,i.kt)("p",null,"For example, the following code:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from pydantic import Field\nfrom datahub.api.configuration.common import ConfigModel\n\nclass LookerAPIConfig(ConfigModel):\n    client_id: str = Field(description="Looker API client id.")\n    client_secret: str = Field(description="Looker API client secret.")\n    base_url: str = Field(\n        description="Url to your Looker instance: `https://company.looker.com:19999` or `https://looker.company.com`, or similar. Used for making API calls to Looker and constructing clickable dashboard and chart urls."\n    )\n    transport_options: Optional[TransportOptionsConfig] = Field(\n        default=None,\n        description="Populates the [TransportOptions](https://github.com/looker-open-source/sdk-codegen/blob/94d6047a0d52912ac082eb91616c1e7c379ab262/python/looker_sdk/rtl/transport.py#L70) struct for looker client",\n    )\n')),(0,i.kt)("p",null,"generates the following documentation:\n",(0,i.kt)("img",{alt:"Generated Config Documentation",src:n(8962).Z})),(0,i.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"Inline markdown or code snippets are not yet supported for field level documentation."))),(0,i.kt)("h3",{id:"2-set-up-the-reporter"},"2. Set up the reporter"),(0,i.kt)("p",null,"The reporter interface enables the source to report statistics, warnings, failures, and other information about the run.\nSome sources use the default ",(0,i.kt)("inlineCode",{parentName:"p"},"SourceReport")," class, but others inherit and extend that class."),(0,i.kt)("h3",{id:"3-implement-the-source-itself"},"3. Implement the source itself"),(0,i.kt)("p",null,"The core for the source is the ",(0,i.kt)("inlineCode",{parentName:"p"},"get_workunits")," method, which produces a stream of metadata events (typically MCP objects) wrapped up in a MetadataWorkUnit.\nThe ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/file.py"},"file source")," is a good and simple example."),(0,i.kt)("p",null,"The MetadataChangeEventClass is defined in the metadata models which are generated\nunder ",(0,i.kt)("inlineCode",{parentName:"p"},"metadata-ingestion/src/datahub/metadata/schema_classes.py"),". There are also\nsome ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/emitter/mce_builder.py"},"convenience methods")," for commonly used operations."),(0,i.kt)("h3",{id:"4-set-up-the-dependencies"},"4. Set up the dependencies"),(0,i.kt)("p",null,"Declare the source's pip dependencies in the ",(0,i.kt)("inlineCode",{parentName:"p"},"plugins")," variable of the ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/setup.py"},"setup script"),"."),(0,i.kt)("h3",{id:"5-enable-discoverability"},"5. Enable discoverability"),(0,i.kt)("p",null,"Declare the source under the ",(0,i.kt)("inlineCode",{parentName:"p"},"entry_points")," variable of the ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/setup.py"},"setup script"),". This enables the source to be\nlisted when running ",(0,i.kt)("inlineCode",{parentName:"p"},"datahub check plugins"),", and sets up the source's shortened alias for use in recipes."),(0,i.kt)("h3",{id:"6-write-tests"},"6. Write tests"),(0,i.kt)("p",null,"Tests go in the ",(0,i.kt)("inlineCode",{parentName:"p"},"tests")," directory. We use the ",(0,i.kt)("a",{parentName:"p",href:"https://pytest.org/"},"pytest framework"),"."),(0,i.kt)("h3",{id:"7-write-docs"},"7. Write docs"),(0,i.kt)("h4",{id:"71-set-up-the-source-class-for-automatic-documentation"},"7.1 Set up the source class for automatic documentation"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Indicate the platform name that this source class produces metadata for using the ",(0,i.kt)("inlineCode",{parentName:"li"},"@platform_name")," decorator. We prefer using the human-readable platform name, so e.g. BigQuery (not bigquery)."),(0,i.kt)("li",{parentName:"ul"},"Indicate the config class being used by the source by using the ",(0,i.kt)("inlineCode",{parentName:"li"},"@config_class")," decorator."),(0,i.kt)("li",{parentName:"ul"},"Indicate the support status of the connector by using the ",(0,i.kt)("inlineCode",{parentName:"li"},"@support_status")," decorator."),(0,i.kt)("li",{parentName:"ul"},"Indicate what capabilities the connector supports (and what important capabilities it does NOT support) by using the ",(0,i.kt)("inlineCode",{parentName:"li"},"@capability")," decorator."),(0,i.kt)("li",{parentName:"ul"},"Add rich documentation for the connector by utilizing docstrings on your Python class. Markdown is supported.")),(0,i.kt)("p",null,"See below a simple example of how to do this for any source."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'\nfrom datahub.ingestion.api.decorators import (\n    SourceCapability,\n    SupportStatus,\n    capability,\n    config_class,\n    platform_name,\n    support_status,\n)\n\n@platform_name("File")\n@support_status(SupportStatus.CERTIFIED)\n@config_class(FileSourceConfig)\n@capability(\n    SourceCapability.PLATFORM_INSTANCE,\n    "File based ingestion does not support platform instances",\n    supported=False,\n)\n@capability(SourceCapability.DOMAINS, "Enabled by default")\n@capability(SourceCapability.DATA_PROFILING, "Optionally enabled via configuration")\n@capability(SourceCapability.DESCRIPTIONS, "Enabled by default")\n@capability(SourceCapability.LINEAGE_COARSE, "Enabled by default")\nclass FileSource(Source):\n   """\n   \n   The File Source can be used to produce all kinds of metadata from a generic metadata events file. \n   :::note\n   Events in this file can be in MCE form or MCP form.\n   :::\n   \n   """\n\n   ... source code goes here\n\n')),(0,i.kt)("h4",{id:"72-write-custom-documentation"},"7.2 Write custom documentation"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Create a copy of ",(0,i.kt)("a",{parentName:"li",href:"/docs/metadata-ingestion/source-docs-template"},(0,i.kt)("inlineCode",{parentName:"a"},"source-docs-template.md"))," and edit all relevant components. "),(0,i.kt)("li",{parentName:"ul"},"Name the document as ",(0,i.kt)("inlineCode",{parentName:"li"},"<plugin.md>")," and move it to ",(0,i.kt)("inlineCode",{parentName:"li"},"metadata-ingestion/docs/sources/<platform>/<plugin>.md"),". For example for the Kafka platform, under the ",(0,i.kt)("inlineCode",{parentName:"li"},"kafka")," plugin, move the document to ",(0,i.kt)("inlineCode",{parentName:"li"},"metadata-ingestion/docs/sources/kafka/kafka.md"),"."),(0,i.kt)("li",{parentName:"ul"},"Add a quickstart recipe corresponding to the plugin under ",(0,i.kt)("inlineCode",{parentName:"li"},"metadata-ingestion/docs/sources/<platform>/<plugin>_recipe.yml"),". For example, for the Kafka platform, under the ",(0,i.kt)("inlineCode",{parentName:"li"},"kafka")," plugin, there is a quickstart recipe located at ",(0,i.kt)("inlineCode",{parentName:"li"},"metadata-ingestion/docs/sources/kafka/kafka_recipe.yml"),"."),(0,i.kt)("li",{parentName:"ul"},"To write platform-specific documentation (that is cross-plugin), write the documentation under ",(0,i.kt)("inlineCode",{parentName:"li"},"metadata-ingestion/docs/sources/<platform>/README.md"),". For example, cross-plugin documentation for the BigQuery platform is located under ",(0,i.kt)("inlineCode",{parentName:"li"},"metadata-ingestion/docs/sources/bigquery/README.md"),".")),(0,i.kt)("h4",{id:"73-viewing-the-documentation"},"7.3 Viewing the Documentation"),(0,i.kt)("p",null,"Documentation for the source can be viewed by running the documentation generator from the ",(0,i.kt)("inlineCode",{parentName:"p"},"docs-website")," module. "),(0,i.kt)("h5",{id:"step-1-build-the-ingestion-docs"},"Step 1: Build the Ingestion docs"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"# From the root of DataHub repo\n./gradlew :metadata-ingestion:docGen\n")),(0,i.kt)("p",null,"If this finishes successfully, you will see output messages like:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},'Ingestion Documentation Generation Complete\n############################################\n{\n  "source_platforms": {\n    "discovered": 40,\n    "generated": 40\n  },\n  "plugins": {\n    "discovered": 47,\n    "generated": 47,\n    "failed": 0\n  }\n}\n############################################\n')),(0,i.kt)("p",null,"You can also find documentation files generated at ",(0,i.kt)("inlineCode",{parentName:"p"},"./docs/generated/ingestion/sources")," relative to the root of the DataHub repo. You should be able to locate your specific source's markdown file here and investigate it to make sure things look as expected."),(0,i.kt)("h4",{id:"step-2-build-the-entire-documentation"},"Step 2: Build the Entire Documentation"),(0,i.kt)("p",null,"To view how this documentation looks in the browser, there is one more step. Just build the entire docusaurus page from the ",(0,i.kt)("inlineCode",{parentName:"p"},"docs-website")," module. "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"# From the root of DataHub repo\n./gradlew :docs-website:build\n")),(0,i.kt)("p",null,"This will generate messages like:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},'...\n> Task :docs-website:yarnGenerate\nyarn run v1.22.0\n$ rm -rf genDocs/* && ts-node -O \'{ "lib": ["es2020"], "target": "es6" }\' generateDocsDir.ts && mv -v docs/* genDocs/\nIncluding untracked files in docs list:\ndocs/graphql -> genDocs/graphql\nDone in 2.47s.\n\n> Task :docs-website:yarnBuild\nyarn run v1.22.0\n$ docusaurus build\n\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\u2502                                                                              \u2502\u2502                Update available 2.0.0-beta.8 \u2192 2.0.0-beta.18                 \u2502\u2502                                                                              \u2502\u2502       To upgrade Docusaurus packages with the latest version, run the        \u2502\u2502                             following command:                               \u2502\u2502                    yarn upgrade @docusaurus/core@latest                      \u2502\u2502   @docusaurus/plugin-ideal-image@latest @docusaurus/preset-classic@latest    \u2502\u2502                                                                              \u2502\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n\n[en] Creating an optimized production build...\nInvalid docusaurus-plugin-ideal-image version 2.0.0-beta.7.\nAll official @docusaurus/* packages should have the exact same version as @docusaurus/core (2.0.0-beta.8).\nMaybe you want to check, or regenerate your yarn.lock or package-lock.json file?\nBrowserslist: caniuse-lite is outdated. Please run:\n  npx browserslist@latest --update-db\n  Why you should do it regularly: https://github.com/browserslist/browserslist#browsers-data-updating\n\u2139 Compiling Client\n\u2139 Compiling Server\n\u2714 Client: Compiled successfully in 1.95s\n\u2714 Server: Compiled successfully in 7.52s\nSuccess! Generated static files in "build".\n\nUse `npm run serve` command to test your build locally.\n\nDone in 11.59s.\n\nDeprecated Gradle features were used in this build, making it incompatible with Gradle 7.0.\nUse \'--warning-mode all\' to show the individual deprecation warnings.\nSee https://docs.gradle.org/6.9.2/userguide/command_line_interface.html#sec:command_line_warnings\n\nBUILD SUCCESSFUL in 35s\n36 actionable tasks: 16 executed, 20 up-to-date\n')),(0,i.kt)("p",null,"After this you need to run the following script from the ",(0,i.kt)("inlineCode",{parentName:"p"},"docs-website")," module. "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"cd docs-website\nnpm run serve\n")),(0,i.kt)("p",null,"Now, browse to http://localhost:3000 or whichever port npm is running on, to browse the docs.\nYour source should show up on the left sidebar under ",(0,i.kt)("inlineCode",{parentName:"p"},"Metadata Ingestion / Sources"),". "),(0,i.kt)("h3",{id:"8-add-sql-alchemy-mapping-if-applicable"},"8. Add SQL Alchemy mapping (if applicable)"),(0,i.kt)("p",null,"Add the source in ",(0,i.kt)("inlineCode",{parentName:"p"},"get_platform_from_sqlalchemy_uri")," function\nin ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/sql/sql_common.py"},"sql_common.py")," if the source has an sqlalchemy source"),(0,i.kt)("h3",{id:"9-add-logo-for-the-platform"},"9. Add logo for the platform"),(0,i.kt)("p",null,"Add the logo image in ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/datahub-web-react/src/images"},"images folder")," and add it to be ingested at ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/datahub-project/datahub/blob/master/metadata-service/war/src/main/resources/boot/data_platforms.json"},"startup")))}p.isMDXComponent=!0},8962:function(e,t,n){t.Z=n.p+"assets/images/generated_config_docs-f6dd5cda042a12e207db5ab84513fa4f.png"}}]);